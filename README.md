# Проект fasta_protein_sync
Программа предназначена для высокопроизводительного анализа FASTA-файлов. Она классифицирует аминокислоты по их физико-химическим свойствам (гидрофобные, нейтральные, положительно/отрицательно заряженные) и сравнивает эффективность различных подходов к параллелизации в Python.

**Основные возможности:**
- Парсинг FASTA: Использование библиотеки Biopython для корректной обработки биологических данных.
- Многопоточность (threading): Попытка ускорения через разделение задач внутри одного процесса.
- Многопроцессность (multiprocessing): Использование нескольких ядер CPU для обхода GIL (Global Interpreter Lock).
- Синхронизация: Безопасный подсчет общих агрегированных данных с использованием очередей (Queue) или блокировок.

## Скопировать проект
```bash
git clone https://github.com/Uminelka/fasta_protein_sync.git
cd fasta_protein_sync
```

## Виртуальное окружение и зависимости
```bash
# Создание окружения
python -m venv venv
# Активация окружения
.\venv\Scripts\activate
# Установка зависимостей
pip install -r requirements.txt
```

## Как пользоваться
Основные файлы:
1. *`fasta_separator.py`* - разделяет файл формата .fasta на отдельные файлы размером 100, 1000, 10000 и 100к последовательностей.
2. *`fasta_reader.py`* - анализирует файл формата .fasta в обычном режиме.
3. *`fasta_threading.py`* - анализирует файл формата .fasta в многопоточном режиме.
4. *`fasta_multiprocessing.py`* - анализирует файл формата .fasta в многопроцессном режиме.

## Графики
В файле *`graphs.py`* строются гистограммы на основе полученных данных.

**1. График зависимости времени выполнения программы от количества входных последовательностей в разном режиме работы программы при фиксированном, не очень большом количестве потоков/процессов:**

  <img width="1493" height="902" alt="image" src="https://github.com/user-attachments/assets/7fc17c32-ed7e-42f2-8e8c-ab56af3c87e3" />

*Вывод по графику:*

- Когда данных мало, особой разницы в скорости нет. Но если использовать процессы, программа может работать даже чуть медленнее, потому что компьютеру нужно потратить лишнее время на запуск этих самых процессов.
- Когда данных становится много (например, 300 000 последовательностей), тут уже процессы вырываются вперед. Они справляются с задачей почти в два раза быстрее, чем обычная однопоточная программа.
- А вот потоки на больших объемах работают плохо. Подсчет аминокислот — это задача, которая грузит процессор. А в Python потоки не могут одновременно крутиться на разных ядрах из-за глобальной блокировки (GIL). В итоге они только мешают друг другу и тратят время не на подсчеты, а на выяснение, кто из них сейчас работает.

**2. График зависимости времени выполнения от числа потоков, процессов при большом входном файле фиксированного размера:**
   
<img width="1442" height="868" alt="image" src="https://github.com/user-attachments/assets/0fdf97c5-18eb-4b44-bc24-4381d498d746" />

*Вывод по графику:*

- Потоки: График растет вверх. То есть, чем больше потоков мы создаем, тем дольше программа работает. Это доказывает, что для сложных вычислений потоки в Python бесполезны: они только создают видимость работы, а на самом деле тратят время на постоянное переключение друг между другом.
- Процессы: Тут график сначала резко падает вниз (с 1 до 4 процессов — скорость растет), а потом снова ползет вверх. Лучше всего программа работала на 4 процессах. Когда мы запустили 12 процессов, времени потребовалось снова больше.
- В процессоре всего 4 ядра. Пока задач не больше, чем ядер, компьютер работает быстро. А когда мы даем ему 12 задач одновременно, он начинает суетиться: останавливает один процесс, запускает другой, чтобы все успели поработать. Из-за этой суеты толку от параллельной работы уже нет, и время выполнения снова растет.
